/**** Start of imports. If edited, may not auto-convert in the playground. ****/
var dryCool = ee.ImageCollection("projects/servir-mekong/usgs_sr_composites/drycool"),
    dryHot = ee.ImageCollection("projects/servir-mekong/usgs_sr_composites/dryhot"),
    rainy = ee.ImageCollection("projects/servir-mekong/usgs_sr_composites/rainy");
/***** End of imports. If edited, may not auto-convert in the playground. *****/
// define a study area
var sa = ee.FeatureCollection("projects/servir-mekong/CambodiaFireEmissions/Forest_Fire_Study_Area");
Map.addLayer(sa, {}, 'study area',false);

// choose classifier 
var classifier = ee.Classifier.randomForest;

// choose classifier parameters
var classifierParameters = {numberOfTrees:100};

// choose classifier output mode: CLASSIFICATION, REGRESSION, PROBABILITY
var mode = 'PROBABILITY';

// choose projection4
var crs = 'EPSG:4326';

// choose resolution
var scale = 30;

// choose export name
var exportName = 'Forest_NonForest';

// set the sample size
var sampleSize = 1000;

// choose the predictor bands
var predictBands = ['green', 'red', 'nir', 'swir1', 'swir2','ndvi', 'nbr', 'ndii', 'ndwi2'];

///////////////////////////////////////////////////////////////////////////////////////////
// predict forest change (loss only) prior to the year 2000
// create a change model between the years 2000 and 2017
// apply that model to all years prior to 2000
///////////////////////////////////////////////////////////////////////////////////////////
// join collections to a single collection
var mergedCollections = dryCool;//.merge(dryHot).merge(rainy);
print('merged collections', mergedCollections);

// filter the collections to get only the medoid images and remove thermal bands
var medoidCollections = mergedCollections.filter(ee.Filter.stringContains({leftField: 'compositingMethod', rightValue: 'Medoid'}))
                        .select(0,1,2,3,4,5);
print('medoidCollections', medoidCollections);

// function to add normalized difference to collection
function normalizedDifference(img){
  img = img.addBands(img.normalizedDifference(['nir', 'red']).rename('ndvi'));
  img = img.addBands(img.normalizedDifference(['nir', 'swir2']).rename('nbr'));
  img = img.addBands(img.normalizedDifference(['green', 'swir1']).rename('ndii'));
  img = img.addBands(img.normalizedDifference(['nir', 'swir2']).rename('ndwi2'));
  return img;
}

var medoidIndex = medoidCollections.map(normalizedDifference);
print('medoidIndex', medoidIndex);

// set the years to train the change model to
var startYearTrain = 2001;
var endYearTrain = 2016;
// set the years to apply the change model to
var startYearApply = 1987;
var endYearApply = 1999;

// get a list of years for training the model
var trainYears = ee.List.sequence(startYearTrain, endYearTrain);
// get a list of years for applying the model
var applyYears = ee.List.sequence(startYearApply, endYearApply);

// get the Hansen data
var changeReferenceData = ee.Image('UMD/hansen/global_forest_change_2017_v1_5').select(3);

// generate random points to sample with
var randomPoints = ee.FeatureCollection.randomPoints({region:sa, points: 1000, seed:0});

// function to get pairwise differences
var samplePairwiseDifferences = trainYears.map(function(year){
  var lossYear = ee.Number(year).subtract(2000);
  var priorYear = ee.Number(year).subtract(1);
  var refData = changeReferenceData.eq(lossYear);
  var year1 = medoidIndex.filter(ee.Filter.eq('startyear', ee.Number(year))).select(predictBands).first().clip(sa);
  var year2 = medoidIndex.filter(ee.Filter.eq('startyear', priorYear)).select(predictBands).first().clip(sa);
  var diff = ee.Image(year1).subtract(ee.Image(year2));
  var sampleImage = refData.addBands(diff);
  //var samplePoints = sampleImage.sampleRegions(randomPoints)
  var sample = sampleImage.sample({region: sa, scale: 30, numPixels: sampleSize});
  return sample;
});
print('samplePairwiseDifferences', samplePairwiseDifferences);

// convert output to a feature collection, flatten, and add a random value column
// so that the sample can be balanced
var spdFC = ee.FeatureCollection(samplePairwiseDifferences).flatten();
spdFC = spdFC.randomColumn('rand', 456768);
print('sample pairwise differences feature collection', spdFC.limit(5));
spdFC = spdFC.sort('rand');

var change = spdFC.filter(ee.Filter.gte('lossyear', 1));
var noChange = spdFC.filter(ee.Filter.eq('lossyear', 0)).limit(change.size());
var changeNoChange = change.merge(noChange);
// print the number of change samples
print('change sample size', change.size());

// get the model input properties
var changeInputProperties = samplePairwiseDifferences.get(0);
changeInputProperties = ee.FeatureCollection(changeInputProperties).first()
                        .propertyNames().remove('lossyear').remove('system:index');
print('changeInputProperties', changeInputProperties);

// create the random forest classifier  
var changeModel = classifier(classifierParameters).setOutputMode(mode).train({
  features: changeNoChange,
  classProperty: 'lossyear',
  inputProperties: changeInputProperties, 
  subsampling: 1,
  subsamplingSeed: 0});
print('changeModel', changeModel);

// get confusion matrix
//var changeConfusionMatrix = changeModel.confusionMatrix();
//print('changeConfusionMatrix', changeConfusionMatrix);

// apply the model to each year
var applyModel = applyYears.map(function(year){
  var priorYear = ee.Number(year).subtract(1);
  var year1 = medoidIndex.filter(ee.Filter.eq('startyear', year)).select(predictBands).first().clip(sa);
  var year2 = medoidIndex.filter(ee.Filter.eq('startyear',priorYear)).select(predictBands).first().clip(sa);
  var diff = ee.Image(year1).subtract(ee.Image(year2));
  var predict = diff.classify(changeModel); 
  predict = predict.set('year', year);
  return predict;
});
applyModel = ee.ImageCollection(applyModel);
print('apply model', applyModel);
Map.addLayer(applyModel.first().gte(0.75), {min:0, max:1}, 'change');

// create year of disturbance image composite 
var cumulativeChange = function(image){
  var year = image.get('year')
  var zeroConstant = ee.Image(0)
  var t = ee.Algorithms.If(year.gt(0), image, zeroConstant);
}


var c = collection.iterate(ee.Algorithms.If(image.eq(1), year, zeroConstant))

//var hansen = changeReferenceData.updateMask(changeReferenceData.gte(startYearApply-2000).and(changeReferenceData.lte(endYearApply-2000)));
//Map.addLayer(hansen, {min:startYearApply-2000, max:endYearApply-2000,palette:'FF0,F00'}, 'hansen ref', false);

///////////////////////////////////////////////////////////////////////////////////////////
// model forest/non-forest
// create a forest/non-forest model for the year 2000
// apply that model to all years after 2000
///////////////////////////////////////////////////////////////////////////////////////////

// var predictors = ee.ImageCollection("projects/servir-mekong/CambodiaFireEmissions/forest-mapping-ls-ts");
// predictors = predictors.select([0,1,2,3,4,5]);
// print(predictors);

// // set a threshold for forest cover
// var covThresh = 20;

// // get the Hansen modeled tree cover in the year 2000 as the reference data
// var referenceData = ee.Image('UMD/hansen/global_forest_change_2017_v1_5').select(0);
// referenceData = referenceData.gt(covThresh).clip(sa);
// print('referenceData', referenceData);

// // get landsat data from the year 2000 to use as explanatory variables in a random forest model
// var xVars = predictors.filterMetadata('system:time_start', 'equals', 959817600000);
// // convert it from an image collection to an image
// xVars = xVars.median();
// print('xVars', xVars);

// // create the composite image to be sampled
// var sampleImage = referenceData.addBands(xVars);

// // Sample the training image to get the training data
// var trainingData = sampleImage.sample({
//   region: sa, 
//   scale: 30, 
//   numPixels: sampleSize
// });
// //print('training data', trainingData.limit(5));

// // set the model input properties
// var inputProperties = ee.Feature(trainingData.first()).propertyNames();
// inputProperties = inputProperties.remove('system:index').remove('treecover2000');
// print('inputProperties', inputProperties);

// // get column name of reference field as a string
// var responseField = 'treecover2000';
  
// // create the random forest classifier  
// var model = classifier(classifierParameters).setOutputMode(mode).train({
//   features: trainingData,
//   classProperty: responseField,
//   inputProperties: inputProperties, 
//   subsampling: 1,
//   subsamplingSeed: 0});
// print('model', model);

// // get confusion matrix
// var confusionMatrix = model.confusionMatrix();
// print('confusionMatrix', confusionMatrix);
  
// // map the classification function across each image in a collection 
// var test = predictors.map(function(img){return classificationWrapper(img,model)});
// print('test:', test);

// // export the classified result
// //Export.image.toDrive({image: test[1], description: exportName, region: sa, scale: scale, crs: crs, maxPixels: 1e13});

// // add the classified result to the map
// Map.addLayer(test.select(0), {min:0, max:1}, 'forest');

// ///////////////////////////////////////////////////////////////////////////////////////////////
// // classification 
// ///////////////////////////////////////////////////////////////////////////////////////////////
// function classificationWrapper(image, model){
//   image = ee.Image(image);

//   // apply the model to each image in the collection
//   var applyModel = image.classify(model);
  
//   return applyModel;
// }






